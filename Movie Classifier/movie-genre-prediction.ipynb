{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<H1> Import nacessary libaries","metadata":{"id":"baoDZvEHUb8T"}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom gensim.models import Word2Vec\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"id":"Kk_RmLVoUj95","execution":{"iopub.status.busy":"2023-09-03T15:54:56.048918Z","iopub.execute_input":"2023-09-03T15:54:56.049526Z","iopub.status.idle":"2023-09-03T15:54:57.747882Z","shell.execute_reply.started":"2023-09-03T15:54:56.049491Z","shell.execute_reply":"2023-09-03T15:54:57.746785Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<H1> Import dataset from drive","metadata":{"id":"oo1V6d8vUm2S"}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/train_data.txt\", sep=':::', names=['Title', 'Genre', 'Description'], engine='python')\ntrain_data.head()\n","metadata":{"id":"s4CUECulUuHC","outputId":"361c8e90-4db3-4126-dd33-059bc8dd0810","execution":{"iopub.status.busy":"2023-09-03T15:54:57.749780Z","iopub.execute_input":"2023-09-03T15:54:57.750099Z","iopub.status.idle":"2023-09-03T15:54:58.717246Z","shell.execute_reply.started":"2023-09-03T15:54:57.750071Z","shell.execute_reply":"2023-09-03T15:54:58.716134Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                Title       Genre  \\\n1       Oscar et la dame rose (2009)       drama    \n2                       Cupid (1997)    thriller    \n3   Young, Wild and Wonderful (1980)       adult    \n4              The Secret Sin (1915)       drama    \n5             The Unrecovered (2007)       drama    \n\n                                         Description  \n1   Listening in to a conversation between his do...  \n2   A brother and sister with a past incestuous r...  \n3   As the bus empties the students for their fie...  \n4   To help their unemployed father make ends mee...  \n5   The film's title refers not only to the un-re...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Genre</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Oscar et la dame rose (2009)</td>\n      <td>drama</td>\n      <td>Listening in to a conversation between his do...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cupid (1997)</td>\n      <td>thriller</td>\n      <td>A brother and sister with a past incestuous r...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Young, Wild and Wonderful (1980)</td>\n      <td>adult</td>\n      <td>As the bus empties the students for their fie...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Secret Sin (1915)</td>\n      <td>drama</td>\n      <td>To help their unemployed father make ends mee...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The Unrecovered (2007)</td>\n      <td>drama</td>\n      <td>The film's title refers not only to the un-re...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/test_data.txt\", sep=':::', names=['Title', 'Description'], engine='python')\ntest_data.head()\n\n","metadata":{"id":"7RBM52OAVDIa","outputId":"90ad70b3-5ad8-4609-98fb-2e852f4c0f35","execution":{"iopub.status.busy":"2023-09-03T15:54:58.718373Z","iopub.execute_input":"2023-09-03T15:54:58.719101Z","iopub.status.idle":"2023-09-03T15:54:59.448126Z","shell.execute_reply.started":"2023-09-03T15:54:58.719068Z","shell.execute_reply":"2023-09-03T15:54:59.447011Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                           Title  \\\n1          Edgar's Lunch (1998)    \n2      La guerra de papá (1977)    \n3   Off the Beaten Track (2010)    \n4        Meu Amigo Hindu (2015)    \n5             Er nu zhai (1955)    \n\n                                         Description  \n1   L.R. Brane loves his life - his car, his apar...  \n2   Spain, March 1964: Quico is a very naughty ch...  \n3   One year in the life of Albin and his family ...  \n4   His father has died, he hasn't spoken with hi...  \n5   Before he was known internationally as a mart...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Edgar's Lunch (1998)</td>\n      <td>L.R. Brane loves his life - his car, his apar...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>La guerra de papá (1977)</td>\n      <td>Spain, March 1964: Quico is a very naughty ch...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Off the Beaten Track (2010)</td>\n      <td>One year in the life of Albin and his family ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Meu Amigo Hindu (2015)</td>\n      <td>His father has died, he hasn't spoken with hi...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Er nu zhai (1955)</td>\n      <td>Before he was known internationally as a mart...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"combined_data = pd.concat([train_data, test_data], ignore_index=True)\ndata = combined_data","metadata":{"id":"d24LK_x3VNgz","execution":{"iopub.status.busy":"2023-09-03T15:54:59.450984Z","iopub.execute_input":"2023-09-03T15:54:59.451626Z","iopub.status.idle":"2023-09-03T15:54:59.467325Z","shell.execute_reply.started":"2023-09-03T15:54:59.451580Z","shell.execute_reply":"2023-09-03T15:54:59.466391Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"<h1> Data Preprocessing and Features Extraction","metadata":{"id":"6KCVnaLGVPwr"}},{"cell_type":"code","source":"\ndata = data.dropna()\ncorpus = data[\"Description\"].apply(lambda x: re.findall(r'\\w+', x.lower()))\nword2vec_model = Word2Vec(corpus, vector_size=100, window=5, min_count=1, workers=4)\n\ndef get_sentence_embedding(sentence):\n    words = re.findall(r'\\w+', sentence.lower())\n    vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n    return sum(vectors) / len(vectors) if vectors else [0] * 100\n\ndata[\"embeddings\"] = data[\"Description\"].apply(get_sentence_embedding)\nX = pd.DataFrame(data[\"embeddings\"].to_list())\n\nlabel_encoder = LabelEncoder()\ndata[\"genre_encoded\"] = label_encoder.fit_transform(data[\"Genre\"])\ny = data[\"genre_encoded\"]","metadata":{"id":"McT0UrFsVO0E","outputId":"3bcb536d-09d7-46e8-872e-9c693ffa4d66","execution":{"iopub.status.busy":"2023-09-03T15:55:25.617584Z","iopub.execute_input":"2023-09-03T15:55:25.618040Z","iopub.status.idle":"2023-09-03T15:56:13.863390Z","shell.execute_reply.started":"2023-09-03T15:55:25.618008Z","shell.execute_reply":"2023-09-03T15:56:13.862487Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression  # Add this import\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report, confusion_matrix\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nmodel = LogisticRegression(random_state=42)\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(X_test)\n\nprecision = precision_score(y_test, predictions, average='weighted')\nrecall = recall_score(y_test, predictions, average='weighted')\naccuracy = accuracy_score(y_test, predictions)\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"Accuracy:\", accuracy)\n\nprint(classification_report(y_test, predictions))\n\nconfusion_mat = confusion_matrix(y_test, predictions)\nprint(\"Confusion Matrix:\")\nprint(confusion_mat)\n","metadata":{"id":"59KkNMk-WfRs","outputId":"f454d651-d9e7-460a-82f0-dc812820c8c0","execution":{"iopub.status.busy":"2023-09-03T15:57:21.901136Z","iopub.execute_input":"2023-09-03T15:57:21.901661Z","iopub.status.idle":"2023-09-03T15:57:29.610491Z","shell.execute_reply.started":"2023-09-03T15:57:21.901627Z","shell.execute_reply":"2023-09-03T15:57:29.609422Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Precision: 0.4782857902735871\nRecall: 0.5266070275753942\nAccuracy: 0.5266070275753942\n              precision    recall  f1-score   support\n\n           0       0.30      0.21      0.25       259\n           1       0.45      0.18      0.26       114\n           2       0.14      0.03      0.04       154\n           3       1.00      0.01      0.02        86\n           4       0.00      0.00      0.00        52\n           5       0.44      0.48      0.46      1497\n           6       0.00      0.00      0.00       106\n           7       0.64      0.83      0.72      2609\n           8       0.51      0.74      0.61      2705\n           9       0.33      0.02      0.05       161\n          10       0.00      0.00      0.00        58\n          11       0.57      0.53      0.55        45\n          12       0.00      0.00      0.00        48\n          13       0.44      0.37      0.40       458\n          14       0.43      0.41      0.42       128\n          15       0.00      0.00      0.00        54\n          16       0.00      0.00      0.00        56\n          17       0.00      0.00      0.00        37\n          18       0.35      0.17      0.23       165\n          19       0.42      0.04      0.08       119\n          20       0.39      0.23      0.29       115\n          21       0.43      0.21      0.28      1060\n          22       0.51      0.28      0.36        99\n          23       0.33      0.05      0.09        95\n          24       0.22      0.06      0.10       324\n          25       0.00      0.00      0.00        24\n          26       0.64      0.65      0.65       215\n\n    accuracy                           0.53     10843\n   macro avg       0.32      0.20      0.22     10843\nweighted avg       0.48      0.53      0.48     10843\n\nConfusion Matrix:\n[[  55    1    3    0    0   37    1   25   93    0    0    2    0   11\n     1    0    0    0    2    0    4    4    3    0    4    0   13]\n [   1   21    2    0    0   47    0    4   25    0    0    0    0    4\n     0    0    0    0    0    0    1    8    0    0    1    0    0]\n [   9    8    4    0    0   13    0   22   53    0    0    1    0   15\n     1    0    0    0    3    1    5    8    0    0    0    0   11]\n [   4    0    4    1    0   19    0   14   21    0    0    0    0   11\n     2    0    0    0    2    0    0    7    0    0    1    0    0]\n [   0    0    0    0    0    0    0   39   12    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    1    0    0    0]\n [  22    3    1    0    0  719    2  104  542    1    0    0    0   20\n     5    0    0    0    6    4    2   39    1    2    5    0   19]\n [   5    0    0    0    0   14    0   11   49    0    0    0    0   10\n     0    0    0    0    0    0    2    3    0    0    9    0    3]\n [   6    1    1    0    0   67    1 2170  219    0    0    2    0    6\n    20    0    0    0   11    0    3   87   11    2    1    0    1]\n [  24    3    0    0    0  276    0  228 2014    2    0    2    0   40\n     1    0    0    0    3    1    3   68    1    0   24    0   15]\n [   2    0    0    0    0   40    0   33   49    4    0    3    0    8\n     8    0    0    0    4    0    2    5    1    2    0    0    0]\n [   3    1    2    0    0    5    0   10   27    0    0    0    0    6\n     0    0    0    0    0    0    0    2    0    0    2    0    0]\n [   2    0    0    0    0    9    0    3    0    0    0   24    0    0\n     0    0    0    0    3    0    1    0    2    1    0    0    0]\n [   0    0    0    0    0    0    0   38    7    0    0    0    0    1\n     1    0    0    0    0    0    0    0    0    0    1    0    0]\n [   9    0    1    0    0   55    0   26  149    0    0    0    0  170\n     3    0    0    0    2    0    7   22    0    0    8    0    6]\n [   0    0    0    0    0   16    0   48    2    0    0    1    0    0\n    52    0    0    0    2    1    0    4    1    1    0    0    0]\n [   2    0    1    0    0   15    0   11   11    1    0    1    0    1\n    10    0    0    0    0    0    0    1    0    0    0    0    0]\n [   1    0    0    0    0    9    1    3   25    0    0    0    0    7\n     0    0    0    0    0    0    1    4    0    0    5    0    0]\n [   1    0    1    0    0    3    0   25    2    0    0    0    0    0\n     0    0    0    0    1    0    0    2    2    0    0    0    0]\n [   3    1    0    0    0   47    0   67    7    1    0    2    0    1\n     3    0    0    0   28    0    0    4    1    0    0    0    0]\n [   1    0    0    0    0   22    1    2   82    0    0    0    0    3\n     0    0    0    0    1    5    0    2    0    0    0    0    0]\n [  10    0    3    0    0    5    0   28   23    0    0    0    0    5\n     0    0    0    0    0    0   26   10    2    0    1    0    2]\n [   7    6    2    0    0  135    1  340  295    1    1    0    0   22\n     3    0    0    0    2    0    8  225    1    0    9    0    2]\n [   2    0    0    0    0    4    0   49    2    0    0    3    0    0\n     3    0    0    0    5    0    0    3   28    0    0    0    0]\n [   1    0    0    0    0   19    0   53    0    2    0    1    0    0\n     7    0    0    0    5    0    0    1    1    5    0    0    0]\n [   8    1    1    0    0   33    2   22  173    0    0    0    0   44\n     0    0    0    0    0    0    2   13    0    0   20    0    5]\n [   5    0    0    0    0    0    0   11    7    0    0    0    0    0\n     0    0    0    0    0    0    0    1    0    0    0    0    0]\n [   3    1    3    0    0   17    0    3   43    0    0    0    0    2\n     0    0    0    0    0    0    0    1    0    1    2    0  139]]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<h1>Genre Prediction","metadata":{"id":"fgB6Hr1fWmrC"}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom gensim.models import Word2Vec\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\n\ndef get_sentence_embedding(sentence):\n    words = re.findall(r'\\w+', sentence.lower())\n    vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n    return sum(vectors) / len(vectors) if vectors else [0] * 100\n\ndef train_model():\n    train_data = pd.read_csv(\"/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/train_data.txt\", sep=':::', names=['Title', 'Genre', 'Description'], engine='python')\n    test_data = pd.read_csv(\"/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/test_data.txt\", sep=':::', names=['Title', 'Description'], engine='python')\n    combined_data = pd.concat([train_data, test_data], ignore_index=True)\n    data = combined_data\n    data = data.dropna()\n    corpus = data[\"Description\"].apply(lambda x: re.findall(r'\\w+', x.lower()))\n    word2vec_model = Word2Vec(corpus, vector_size=100, window=5, min_count=1, workers=4)\n\n\n    def get_sentence_embedding(sentence):\n        words = re.findall(r'\\w+', sentence.lower())\n        vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n        return sum(vectors) / len(vectors) if vectors else [0] * 100\n\n    data[\"embeddings\"] = data[\"Description\"].apply(get_sentence_embedding)\n    X = pd.DataFrame(data[\"embeddings\"].to_list())\n    label_encoder = LabelEncoder()\n    data[\"genre_encoded\"] = label_encoder.fit_transform(data[\"Genre\"])\n    y = data[\"genre_encoded\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train, y_train)\n\n    return model, label_encoder\n\ndef predict_genre(model, label_encoder, new_descriptions):\n    new_embeddings = [get_sentence_embedding(desc) for desc in new_descriptions]\n    new_X = pd.DataFrame(new_embeddings)\n    new_predictions = model.predict(new_X)\n    predicted_genres = label_encoder.inverse_transform(new_predictions)\n\n    return predicted_genres\n\ntrained_model, genre_label_encoder = train_model()\n\nnew_descriptions = [\"A group of friends embark on an adventurous journey.\",\"In a dystopian future, a hero rises to save the world.\",\"A heartwarming story of family and friendship.\"]\n\n\npredicted_genres = predict_genre(trained_model, genre_label_encoder, new_descriptions)\n\nfor desc, genre in zip(new_descriptions, predicted_genres):\n    print(f\"Description: {desc}\")\n    print(f\"Predicted Genre: {genre}\")\n    print()\n","metadata":{"id":"tRmqL--cWzKO","outputId":"caffceab-04e2-41af-8e50-61514fbd5e29","execution":{"iopub.status.busy":"2023-09-03T15:57:29.612721Z","iopub.execute_input":"2023-09-03T15:57:29.613487Z","iopub.status.idle":"2023-09-03T15:59:46.736207Z","shell.execute_reply.started":"2023-09-03T15:57:29.613423Z","shell.execute_reply":"2023-09-03T15:59:46.735067Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_32/1126448303.py:30: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[\"embeddings\"] = data[\"Description\"].apply(get_sentence_embedding)\n/tmp/ipykernel_32/1126448303.py:33: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[\"genre_encoded\"] = label_encoder.fit_transform(data[\"Genre\"])\n","output_type":"stream"},{"name":"stdout","text":"Description: A group of friends embark on an adventurous journey.\nPredicted Genre:  comedy \n\nDescription: In a dystopian future, a hero rises to save the world.\nPredicted Genre:  documentary \n\nDescription: A heartwarming story of family and friendship.\nPredicted Genre:  drama \n\n","output_type":"stream"}]}]}